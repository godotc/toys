{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128513\n",
      "20320\n"
     ]
    }
   ],
   "source": [
    "msg = \"ä½ å¥½ ğŸ˜ -> Hello!\"\n",
    "print(ord(\"ğŸ˜\"))\n",
    "print( ord(\"ä½ \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20320,22909,32,128513,32,45,62,32,72,101,108,108,111,33,"
     ]
    }
   ],
   "source": [
    "ord(\"ä½ \")\n",
    "for i in msg:\n",
    "    print(ord(i), end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xf0\\x9f\\x98\\x81 -> Hello!'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[228,\n",
       " 189,\n",
       " 160,\n",
       " 229,\n",
       " 165,\n",
       " 189,\n",
       " 32,\n",
       " 240,\n",
       " 159,\n",
       " 152,\n",
       " 129,\n",
       " 32,\n",
       " 45,\n",
       " 62,\n",
       " 32,\n",
       " 72,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 33]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(msg.encode(\"utf-8\"))\n",
    "list(msg.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfe\\x00\\x00`O\\x00\\x00}Y\\x00\\x00 \\x00\\x00\\x00\\x01\\xf6\\x01\\x00 \\x00\\x00\\x00-\\x00\\x00\\x00>\\x00\\x00\\x00 \\x00\\x00\\x00H\\x00\\x00\\x00e\\x00\\x00\\x00l\\x00\\x00\\x00l\\x00\\x00\\x00o\\x00\\x00\\x00!\\x00\\x00\\x00'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[255,\n",
       " 254,\n",
       " 0,\n",
       " 0,\n",
       " 96,\n",
       " 79,\n",
       " 0,\n",
       " 0,\n",
       " 125,\n",
       " 89,\n",
       " 0,\n",
       " 0,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 246,\n",
       " 1,\n",
       " 0,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 62,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 72,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 101,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 108,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 108,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 111,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 33,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(msg.encode(\"utf-32\"))\n",
    "list(msg.encode(\"utf-32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ ğŸ˜ -> Hello!\n",
      "[228, 189, 160, 229, 165, 189, 32, 240, 159, 152, 129, 32, 45, 62, 32, 72, 101, 108, 108, 111, 33]\n"
     ]
    }
   ],
   "source": [
    "def foo(a,b):\n",
    "    print(a+b)\n",
    "\n",
    "list(map(foo, [1,2],[3,4]))\n",
    "# list(map(foo, [[1,2],[3,4]]))  it wrong \n",
    "\n",
    "\n",
    "tokens = msg.encode(\"utf-8\")\n",
    "tokens = list(map(int,tokens))\n",
    "print(msg)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228, 189, 160, 229, 165, 189, 32, 240, 159, 152, 129, 32, 45, 62, 32, 72, 101, 108, 108, 111, 33, 32, 87, 104, 97, 116, 32, 116, 104, 101, 32, 104, 101, 108, 108, 32, 105, 115, 32, 116, 104, 105, 115, 32, 119, 111, 114, 108, 100, 239, 188, 129, 32, 117, 116, 102, 42, 63, 32, 228, 187, 128, 228, 185, 136, 228, 185, 177, 228, 184, 131, 229, 133, 171, 231, 179, 159, 231, 154, 132, 228, 184, 156, 232, 165, 191, 229, 149, 138, 229, 149, 138, 229, 149, 138, 229, 149, 138, 230, 148, 190, 229, 129, 135, 229, 149, 138, 231, 139, 172, 231, 171, 139, 230, 136, 191, 233, 151, 180, 229, 149, 138, 231, 154, 132, 231, 166, 187, 229, 188, 128, 230, 161, 136, 228, 190, 139]\n"
     ]
    }
   ],
   "source": [
    "msg = \"ä½ å¥½ ğŸ˜ -> Hello! What the hell is this worldï¼ utf*? ä»€ä¹ˆä¹±ä¸ƒå…«ç³Ÿçš„ä¸œè¥¿å•Šå•Šå•Šå•Šæ”¾å‡å•Šç‹¬ç«‹æˆ¿é—´å•Šçš„ç¦»å¼€æ¡ˆä¾‹\"\n",
    "tokens = list(map(int, msg.encode(\"utf-8\")))\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "stats = get_stats(tokens)\n",
    "# print(stats)\n",
    "# print(sorted(((v, k) for k, v in stats.items()), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 149)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pair = max(stats,key=stats.get)\n",
    "top_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 99, 9, 1]\n",
      "137\n",
      "131\n",
      "[228, 189, 160, 229, 165, 189, 32, 240, 159, 152, 129, 32, 45, 62, 32, 72, 101, 108, 108, 111, 33, 32, 87, 104, 97, 116, 32, 116, 104, 101, 32, 104, 101, 108, 108, 32, 105, 115, 32, 116, 104, 105, 115, 32, 119, 111, 114, 108, 100, 239, 188, 129, 32, 117, 116, 102, 42, 63, 32, 228, 187, 128, 228, 185, 136, 228, 185, 177, 228, 184, 131, 229, 133, 171, 231, 179, 159, 231, 154, 132, 228, 184, 156, 232, 165, 191, 256, 138, 256, 138, 256, 138, 256, 138, 230, 148, 190, 229, 129, 135, 256, 138, 231, 139, 172, 231, 171, 139, 230, 136, 191, 233, 151, 180, 256, 138, 231, 154, 132, 231, 166, 187, 229, 188, 128, 230, 161, 136, 228, 190, 139]\n"
     ]
    }
   ],
   "source": [
    "def merge(ids, pair, new_index):\n",
    "    new_ids=[]\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i<len(ids) and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            new_ids.append(new_index)\n",
    "            i+=2\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "            i+=1\n",
    "    return new_ids\n",
    "\n",
    "print (merge([5,6,6,7,9,1],[6,7], 99))\n",
    "\n",
    "tokens2 = merge(tokens, top_pair, 256)\n",
    "print(len(tokens))\n",
    "print(len(tokens2))\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228, 189, 160, 229, 165, 189, 32, 240, 159, 152, 129, 32, 45, 62, 32, 72, 101, 108, 108, 111, 33, 32, 87, 104, 97, 116, 32, 116, 104, 101, 32, 104, 101, 108, 108, 32, 105, 115, 32, 116, 104, 105, 115, 32, 119, 111, 114, 108, 100, 239, 188, 129, 32, 117, 116, 102, 42, 63, 32, 228, 187, 128, 228, 185, 136, 228, 185, 177, 228, 184, 131, 229, 133, 171, 231, 179, 159, 231, 154, 132, 228, 184, 156, 232, 165, 191, 229, 149, 138, 229, 149, 138, 229, 149, 138, 229, 149, 138, 230, 148, 190, 229, 129, 135, 229, 149, 138, 231, 139, 172, 231, 171, 139, 230, 136, 191, 233, 151, 180, 229, 149, 138, 231, 154, 132, 231, 166, 187, 229, 188, 128, 230, 161, 136, 228, 190, 139]\n",
      "merging (229, 149) into new token256\n",
      "merging (256, 138) into new token257\n",
      "merging (257, 257) into new token258\n",
      "merging (129, 32) into new token259\n",
      "merging (101, 108) into new token260\n",
      "merging (260, 108) into new token261\n",
      "merging (32, 116) into new token262\n",
      "merging (262, 104) into new token263\n",
      "merging (105, 115) into new token264\n",
      "merging (228, 185) into new token265\n",
      "merging (228, 184) into new token266\n",
      "merging (231, 154) into new token267\n",
      "merging (267, 132) into new token268\n",
      "merging (228, 189) into new token269\n",
      "merging (269, 160) into new token270\n",
      "merging (270, 229) into new token271\n",
      "merging (271, 165) into new token272\n",
      "merging (272, 189) into new token273\n",
      "merging (273, 32) into new token274\n",
      "merging (274, 240) into new token275\n"
     ]
    }
   ],
   "source": [
    "msg = \"ä½ å¥½ ğŸ˜ -> Hello! What the hell is this worldï¼ utf*? ä»€ä¹ˆä¹±ä¸ƒå…«ç³Ÿçš„ä¸œè¥¿å•Šå•Šå•Šå•Šæ”¾å‡å•Šç‹¬ç«‹æˆ¿é—´å•Šçš„ç¦»å¼€æ¡ˆä¾‹\"\n",
    "tokens = list(map(int, msg.encode(\"utf-8\")))\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def merge(ids, pair, new_index):\n",
    "    new_ids=[]\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i<len(ids) and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            new_ids.append(new_index)\n",
    "            i+=2\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "            i+=1\n",
    "    return new_ids\n",
    "\n",
    "\n",
    "fin_vocab_size = 276\n",
    "num_merges = fin_vocab_size-256\n",
    "ids = list (tokens)\n",
    "\n",
    "merges={} #(i, i) -> i\n",
    "for i in range(num_merges):\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats,key=stats.get)\n",
    "    idx = 256+i\n",
    "    print(f\"merging {pair} into new token{idx}\")\n",
    "    ids = merge(ids, pair, idx)\n",
    "    merges[pair] = idx\n",
    "\n",
    "# print(ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens length:  137\n",
      "ids length:  96\n",
      "compression ratio: 1.43X\n"
     ]
    }
   ],
   "source": [
    "print(\"tokens length: \" , len(tokens))\n",
    "print(\"ids length: \" , len(ids))\n",
    "print(f\"compression ratio: {len( tokens )/ len(ids) :.2f}X\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `tokenizer`: A translator between raw text and LLM\n",
    "\n",
    "And the `decodeing` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ ğŸ˜ -> Hello! What the hell is this worldï¼ utf*? ä»€ä¹ˆä¹±ä¸ƒå…«ç³Ÿçš„ä¸œè¥¿å•Šå•Šå•Šå•Šæ”¾å‡å•Šç‹¬ç«‹æˆ¿é—´å•Šçš„ç¦»å¼€æ¡ˆä¾‹\n"
     ]
    }
   ],
   "source": [
    "# build vocab from compressed map\n",
    "vocab ={idx: bytes([idx] ) for idx in range(256)}\n",
    "for (p0, p1),idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(ids):\n",
    "    ret = {}\n",
    "    tokens = b\"\".join( vocab[index] for index in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "raw =  decode(ids)\n",
    "print(raw)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Implement the `encode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (104, 101) into new token256\n",
      "merging (256, 108) into new token257\n",
      "merging (257, 108) into new token258\n",
      "merging (258, 111) into new token259\n",
      "merging (259, 32) into new token260\n",
      "merging (260, 119) into new token261\n",
      "merging (261, 111) into new token262\n",
      "merging (262, 114) into new token263\n",
      "merging (263, 108) into new token264\n",
      "merging (264, 100) into new token265\n",
      "merging (265, 33) into new token266\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 56\u001b[0m\n\u001b[0;32m     51\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m merge(tokens, pair, idx)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello world!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[22], line 41\u001b[0m, in \u001b[0;36mencode\u001b[1;34m(raw_text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(raw_text):\n\u001b[0;32m     40\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, raw_text\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m---> 41\u001b[0m     merges\u001b[38;5;241m=\u001b[39m \u001b[43mget_merges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     43\u001b[0m         stats \u001b[38;5;241m=\u001b[39m get_stats(tokens)\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36mget_merges\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_merges):\n\u001b[0;32m     29\u001b[0m     stats \u001b[38;5;241m=\u001b[39m get_stats(ids)\n\u001b[1;32m---> 30\u001b[0m     pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m+\u001b[39m i\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerging \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into new token\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: max() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_stats(tokens):\n",
    "    counts = {}\n",
    "    for pair in zip(tokens, tokens[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def merge(ids, pair, new_index):\n",
    "    new_ids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
    "            new_ids.append(new_index)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "            i += 1\n",
    "    return new_ids\n",
    "\n",
    "\n",
    "def get_merges_table(tokens):\n",
    "    merges = {}  # (i, i) -> i\n",
    "\n",
    "    table_size = 276\n",
    "    num_merges = fin_vocab_size - 256\n",
    "    ids = list(tokens)\n",
    "\n",
    "    for i in range(num_merges):\n",
    "        stats = get_stats(ids)\n",
    "        pair = max(stats, key=stats.get)\n",
    "        idx = 256 + i\n",
    "        print(f\"merging {pair} into new token{idx}\")\n",
    "        ids = merge(ids, pair, idx)\n",
    "        merges[pair] = idx\n",
    "\n",
    "    return merges\n",
    "\n",
    "\n",
    "def encode(raw_text):\n",
    "    tokens = list(map(int, raw_text.encode(\"utf-8\")))\n",
    "    # merges= get_merges(tokens)\n",
    "    while len(tokens) >= 2:\n",
    "        stats = get_stats(tokens)\n",
    "        pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))  # exist or inf?\n",
    "\n",
    "        # nothing else can be merged\n",
    "        if pair not in merges:\n",
    "            break\n",
    "\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "print(encode(\"hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ' world', '!']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "# r\"\"\": This is a raw string literal in Python, used for regular expressions to avoid having to escape backslashes.\n",
    "# |: The pipe symbol is used for alternation, allowing the regex to match any of the patterns separated by it.\n",
    "\n",
    "# \\p{L} \\p{letter} -> letter\n",
    "#'\\s: This matches a single whitespace character.\n",
    "# \\p{N}:  -> numberic character\n",
    "# +:  one or more occurrences of the preceding element.\n",
    "# [^\\s\\p{L}\\p{N}]:  matches any character that is not a whitespace, letter, or numeric character.\n",
    "# \\s+: matches one or more whitespace characters.\n",
    "# (?!\\S): This is a negative lookahead that asserts that what follows is not a non-whitespace character.\n",
    "gpt2_pattern = re.compile(\n",
    "    r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+ | ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    ")\n",
    "\n",
    "print(re.findall(gpt2_pattern, \"hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
